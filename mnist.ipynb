{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST手写数据集是深度学习中的“Hello world”，是深度学习中最容易上手的一个项目。MNIST的任务是让计算机识别手写数据集。该数据集包含70,000张手写数字图像: 60,000张用于训练模型，10,000张用于测试。图像是灰度的，分辨率也仅有28x28像素，因而程序的预处理和运行都很方便。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个网络当中，我们将使用两个卷积层，一个池化层和两个全连接层，这些层将28x28的像素块压缩成9维的向量，并与正确的数字预测结果做比较。一般而言，深度学习的框架由四部分组成：网络结构、损失函数、数据集和优化器。在本次的介绍中，我们会把这四个模块分别解耦进行讲解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们先来导入相关库,运行本程序需要拥有pytorch和anaconda3的环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c011b13d50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 60\n",
    "batch_size_test = 1000\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们来开始尝试导入数据集，这一步的主要目的是将深度学习的图像转换成pytorch能够看懂的数据格式。我们先来创建一个dataset类，并用pytorch的`dataloader`方法加载mnist数据集。在下述的类中，有三个魔法方法。`__init__(self, ...) `方法是类的构造函数，在创建类的新实例时被调用。对于数据集类，`__init__ `方法通常用于初始化或加载数据集。例如，在处理MNIST数据集时，我们可以在这里加载数据集文件，进行预处理（如标准化、转换为Tensor等），并设置任何需要的参数。这个方法只在类的实例被创建时执行一次。`__getitem__(self, index) `方法是为了使实例能够像列表一样通过索引来访问。在数据集类中，`__getitem__ `负责返回与给定索引相对应的数据样本（和标签）。例如，在MNIST数据集中，这个方法将返回第index个图像及其对应的标签。这是实现数据加载的核心，因为它允许DataLoader在训练时逐个或批量地获取数据。而`__len__(self) `方法用于返回可迭代对象中样本的总数。在PyTorch中，DataLoader 使用这个方法来确定每个epoch需要迭代多少次以遍历整个数据集。这对于批处理和计算epoch很重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    data_folder: 文件目录\n",
    "    data_name： 数据文件名\n",
    "    label_name：标签数据文件名\n",
    "\"\"\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将 PIL 图像或 NumPy ndarray 转换为 FloatTensor。\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "    \n",
    "class DatasetProcessing():\n",
    "    def __init__(self, folder, data_name, label_name, transform):\n",
    "        (train_set, train_labels) = self._load_data(folder, data_name, label_name)\n",
    "        self.train_set = train_set\n",
    "        self.train_labels = train_labels\n",
    "        self.transforms = transform\n",
    "      \n",
    "    def _load_data(self, data_folder, data_name, label_name):\n",
    "        with gzip.open(os.path.join(data_folder,label_name), 'rb') as lbpath: # rb表示的是读取二进制数据,lbpath指的就是标签的存放路径。\n",
    "            y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "        with gzip.open(os.path.join(data_folder,data_name), 'rb') as imgpath:\n",
    "            x_train = np.frombuffer(\n",
    "            imgpath.read(), np.uint8, offset=16).reshape(len(y_train), 28, 28)\n",
    "        return (x_train, y_train)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img, target = self.train_set[index], int(self.train_labels[index])\n",
    "        plt.imshow(img, cmap='gray', interpolation='none')\n",
    "        plt.title(\"Ground Truth: {}\".format(target))\n",
    "        img = self.transforms(img)\n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.train_set)\n",
    "\n",
    "train_dataset = DatasetProcessing('./data/',\"train-images-idx3-ubyte.gz\",\"train-labels-idx1-ubyte.gz\", transform = transform)\n",
    "test_dataset = DatasetProcessing('./data/',\"t10k-images-idx3-ubyte.gz\",\"t10k-labels-idx1-ubyte.gz\", transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size_train, \n",
    "                                           shuffle = True\n",
    "                                          )  # 此处的值根据您的数据集进行调整\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size = batch_size_test, \n",
    "                                          shuffle = False\n",
    "                                          ) # 此处的值根据您的数据集进行调整)\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来看下数据集具体的形状吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py:152: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242,  1.0395,  1.1159,  1.6378,  2.7960,  2.7960,  2.2869,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.3777,  0.9377,\n",
       "            1.7396,  2.7706,  2.7833,  2.7833,  2.7833,  2.7833,  2.7578,\n",
       "            2.2996, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.1060,  2.0196,  2.4524,  2.4524,  2.6433,  2.7833,\n",
       "            2.7960,  2.1469,  2.7833,  2.7833,  2.7833,  2.7833,  2.7833,\n",
       "            2.4396, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            0.4413,  2.4142,  2.7833,  2.7833,  2.7833,  2.7833,  2.7833,\n",
       "            0.0722, -0.1824,  0.0722,  0.4031,  2.4269,  2.7833,  2.7833,\n",
       "            1.9051, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            1.9432,  2.7833,  2.7833,  2.7833,  2.6942,  0.9504,  0.2504,\n",
       "           -0.4242, -0.4242, -0.4242,  1.4850,  2.7833,  2.7833,  2.3760,\n",
       "           -0.1696, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.4668,\n",
       "            2.6560,  2.7833,  2.7833,  2.4015,  0.3268, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242,  1.8414,  2.7833,  2.7833,  1.3705,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.9305,\n",
       "            2.7833,  2.7833,  2.0451,  0.4286, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.2078,  0.7213,  2.6306,  2.7833,  2.0451,  0.4286,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6322,\n",
       "            2.1851,  1.9942, -0.1187, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242,  1.1159,  2.7833,  2.7833,  2.2360, -0.1187, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            0.5559,  2.7197,  2.7833,  2.7324,  0.9250, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "            2.7960,  2.7833,  2.7833,  0.8741, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  1.2814,\n",
       "            2.8215,  2.7960,  2.7960,  0.0722, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3478,  1.9051,\n",
       "            2.7960,  2.7833,  0.9377, -0.3988, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.2969,  0.8741,  2.7833,\n",
       "            2.7960,  1.6505, -0.2206, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.2587,  1.7141,  2.7833,  2.7833,\n",
       "            0.9759, -0.3988, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242,  0.0976,  2.7833,  2.7833,  2.3378,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242,  0.0849,  1.5487,  2.7833,  2.2996, -0.0296,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242,  1.6759,  2.7833,  2.7833,  0.9250, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242,  0.1231,  1.8541,  2.7833,  1.4850,  0.0722, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242,  1.3196,  2.7833,  2.3887,  0.0722, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242,  0.4286,  2.7833,  0.5813, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]]),\n",
       " 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前我们已经成功的加载好了数据集。我们将正式开始构建深度学习的神经网络！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (c1): Conv3x3(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (c2): Conv3x3(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (c3): Conv3x3(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "      (1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (rl1): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Conv3x3(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Conv3x3, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, out_dim, kernel_size=3, bias=True), \n",
    "            nn.LeakyReLU(0.1, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.c1 = Conv3x3(1,8)\n",
    "        self.c2 = Conv3x3(8,16)\n",
    "        self.c3 = Conv3x3(16,4)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.rl1 = nn.Linear(100,10)\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.c1(x) # 26x26x8\n",
    "        x = self.c2(x) # 24x24x16\n",
    "        x = self.pool(x) # 12x12x16\n",
    "        x = self.c3(x)# 10x10x4\n",
    "        x = self.pool(x) #5x5x4\n",
    "        x = x.view(-1,100)\n",
    "        x = self.rl1(x)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们来初始化网络和优化器，正式开始训练！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\functional.py:152: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  img = torch.from_numpy(pic.transpose((2, 0, 1))).contiguous()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.309785\n",
      "Train Epoch: 1 [600/60000 (1%)]\tLoss: 2.297111\n",
      "Train Epoch: 1 [1200/60000 (2%)]\tLoss: 2.283958\n",
      "Train Epoch: 1 [1800/60000 (3%)]\tLoss: 2.284429\n",
      "Train Epoch: 1 [2400/60000 (4%)]\tLoss: 2.263595\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.257394\n",
      "Train Epoch: 1 [3600/60000 (6%)]\tLoss: 2.239853\n",
      "Train Epoch: 1 [4200/60000 (7%)]\tLoss: 2.202046\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 2.096262\n",
      "Train Epoch: 1 [5400/60000 (9%)]\tLoss: 1.906199\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.635378\n",
      "Train Epoch: 1 [6600/60000 (11%)]\tLoss: 1.150966\n",
      "Train Epoch: 1 [7200/60000 (12%)]\tLoss: 0.816027\n",
      "Train Epoch: 1 [7800/60000 (13%)]\tLoss: 0.765922\n",
      "Train Epoch: 1 [8400/60000 (14%)]\tLoss: 0.977727\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.627917\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.769366\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m980\u001b[39m:\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m train(\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(epoch):\n\u001b[0;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()    \n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m     12\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     13\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(data)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[5], line 31\u001b[0m, in \u001b[0;36mDatasetProcessing.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m     30\u001b[0m     img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_labels[index])\n\u001b[1;32m---> 31\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(img, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     32\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGround Truth: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target))\n\u001b[0;32m     33\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms(img)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:2695\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2689\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   2690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   2691\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2692\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2693\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[0;32m   2694\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2695\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m   2696\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm, aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[0;32m   2697\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation, alpha\u001b[38;5;241m=\u001b[39malpha, vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[0;32m   2698\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax, origin\u001b[38;5;241m=\u001b[39morigin, extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[0;32m   2699\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   2700\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm, filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   2701\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   2702\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2703\u001b[0m     sci(__ret)\n\u001b[0;32m   2704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:1446\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1448\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1449\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1450\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5663\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[0;32m   5656\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m   5657\u001b[0m                       interpolation\u001b[38;5;241m=\u001b[39minterpolation, origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m   5658\u001b[0m                       extent\u001b[38;5;241m=\u001b[39mextent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   5659\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   5660\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5661\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 5663\u001b[0m im\u001b[38;5;241m.\u001b[39mset_data(X)\n\u001b[0;32m   5664\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[0;32m   5665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5666\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\image.py:697\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage):\n\u001b[0;32m    696\u001b[0m     A \u001b[38;5;241m=\u001b[39m pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[1;32m--> 697\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39msafe_masked_invalid(A, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39muint8 \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    700\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcan_cast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame_kind\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage data of dtype \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m cannot be converted to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    702\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\cbook\\__init__.py:720\u001b[0m, in \u001b[0;36msafe_masked_invalid\u001b[1;34m(x, copy)\u001b[0m\n\u001b[0;32m    718\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mbyteswap(inplace\u001b[38;5;241m=\u001b[39mcopy)\u001b[38;5;241m.\u001b[39mnewbyteorder(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Swap to native order.\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m     xm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mma\u001b[38;5;241m.\u001b[39mmasked_invalid(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    721\u001b[0m     xm\u001b[38;5;241m.\u001b[39mshrink_mask()\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\ma\\core.py:2360\u001b[0m, in \u001b[0;36mmasked_invalid\u001b[1;34m(a, copy)\u001b[0m\n\u001b[0;32m   2333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2334\u001b[0m \u001b[38;5;124;03mMask an array where invalid values occur (NaNs or infs).\u001b[39;00m\n\u001b[0;32m   2335\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2357\u001b[0m \n\u001b[0;32m   2358\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2359\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(a, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2360\u001b[0m res \u001b[38;5;241m=\u001b[39m masked_where(\u001b[38;5;241m~\u001b[39m(np\u001b[38;5;241m.\u001b[39misfinite(a)), a, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m   2361\u001b[0m \u001b[38;5;66;03m# masked_invalid previously never returned nomask as a mask and doing so\u001b[39;00m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;66;03m# threw off matplotlib (gh-22842).  So use shrink=False:\u001b[39;00m\n\u001b[0;32m   2363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39m_mask \u001b[38;5;129;01mis\u001b[39;00m nomask:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\ma\\core.py:1828\u001b[0m, in \u001b[0;36mmasked_where\u001b[1;34m(condition, a, copy)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nomask\n\u001b[0;32m   1824\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m   1825\u001b[0m \u001b[38;5;66;03m#                             Masking functions                               #\u001b[39;00m\n\u001b[0;32m   1826\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m-> 1828\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmasked_where\u001b[39m(condition, a, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1829\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1830\u001b[0m \u001b[38;5;124;03m    Mask an array where a condition is met.\u001b[39;00m\n\u001b[0;32m   1831\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1925\u001b[0m \n\u001b[0;32m   1926\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;66;03m# Make sure that condition is a valid standard-type mask.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr = lr, momentum = momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i * len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()    \n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "            torch.save(model.state_dict(), './model.pth')\n",
    "            torch.save(optimizer.state_dict(), './optimizer.pth')\n",
    "\n",
    "\n",
    "for epoch in n_epochs:\n",
    "    train(epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 7738/10000 (77%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(),lr = lr, momentum = momentum)\n",
    "def test():\n",
    "    model.load_state_dict(torch.load('./model.pth'))\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            output = model(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    print('Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
